{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraping.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himanshu-kashyap/Tutorials/blob/master/bs_reddit_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRX7vamvl1OZ",
        "colab_type": "text"
      },
      "source": [
        "## scraping old.reddit.com "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_VwJQI0-vWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BUvikdO_VGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# div id = sitetable contains all the data\n",
        "url = \"https://old.reddit.com/\"\n",
        "request = urllib.request.Request(url)\n",
        "html = urllib.request.urlopen(request).read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcgEm-Go_v2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# provide html and parser to BS\n",
        "soup = BeautifulSoup(html,'html.parser')    # can also be lxml instead of html parser\n",
        "main_table = soup.find(\"div\",attrs = {'id':'siteTable'})  # div id = siteTable contains everything\n",
        "links = main_table.find_all(\"a\",class_ = \"title\")  # returns a result set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glgTVwCwoiW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a list of dictionaries with text title and url; if url is not starting with html, make it.\n",
        "\n",
        "extracted_records = []\n",
        "for link in links:\n",
        "  title = link.text\n",
        "  url_ = link['href']\n",
        "  if not url_.startswith(\"html\"):\n",
        "    url_ = \"https://old.reddit.com\"+url_\n",
        "  record = {\n",
        "      'title':title,\n",
        "      'url':url_\n",
        "  }\n",
        "  extracted_records.append(record)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHtknj_qojFr",
        "colab_type": "code",
        "outputId": "1963073e-bda5-4d77-8c00-f8377e2b9e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(extracted_records)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'title': 'AITA for telling cashier that wasn’t the girls credit card?', 'url': 'https://old.reddit.com/r/AmItheAsshole/comments/cdypge/aita_for_telling_cashier_that_wasnt_the_girls/'}, {'title': 'Not mine but holy stupidity', 'url': 'https://old.reddit.com/r/ChoosingBeggars/comments/ce3d8f/not_mine_but_holy_stupidity/'}, {'title': 'When pulling a Rabbit out of a hat goes wrong', 'url': 'https://old.reddit.comhttps://gfycat.com/immaculategrouchyamericanbadger'}, {'title': 'Redditors with interesting hobbies- what do you do and why?', 'url': 'https://old.reddit.com/r/AskReddit/comments/cdwvhh/redditors_with_interesting_hobbies_what_do_you_do/'}, {'title': 'America’s Finest.', 'url': 'https://old.reddit.com/r/PublicFreakout/comments/cdwuat/americas_finest/'}, {'title': 'Kellyanne Conway Snaps Back at Reporter: ‘What’s Your Ethnicity?’', 'url': 'https://old.reddit.comhttps://www.thedailybeast.com/kellyanne-conway-snaps-back-at-reporter-whats-your-ethnicity?source=politics&via=rss'}, {'title': \"When the guy spotting you says 'I got your back' and it doesen't mean what you think it means....\", 'url': 'https://old.reddit.comhttps://gfycat.com/bleaksecondbongo'}, {'title': 'Florida man strikes again', 'url': 'https://old.reddit.com/r/MurderedByWords/comments/ce2u48/florida_man_strikes_again/'}, {'title': \"Taika Waititi to Direct 'Thor 4'\", 'url': 'https://old.reddit.comhttps://www.hollywoodreporter.com/heat-vision/taika-waititi-direct-thor-4-1224464'}, {'title': 'Man confesses to rape and murder of U.S. scientist Suzanne Eaton in Crete, police say', 'url': 'https://old.reddit.comhttps://www.cbsnews.com/news/crete-suzanne-eaton-murder-confession-local-suspect-today-police-in-greece-say-2019-07-16/'}, {'title': 'According to a study published today in the journal PNAS, many girls who do every bit as well as their male peers in mathematics may still decide on more humanities-centric careers—because their verbal skills outshine their already high marks in math.', 'url': 'https://old.reddit.comhttps://www.pbs.org/wgbh/nova/article/gender-gap-math-comparative-advantage/'}, {'title': 'The \"boomer artstyle\" starter pack', 'url': 'https://old.reddit.com/r/starterpacks/comments/cdxjj0/the_boomer_artstyle_starter_pack/'}, {'title': 'Dog sniffs out two girls lost in Algonquin Park . The goodest girl.', 'url': 'https://old.reddit.com/r/aww/comments/ce2ftb/dog_sniffs_out_two_girls_lost_in_algonquin_park/'}, {'title': \"Taika Waititi to Direct 'Thor 4' for Marvel as WB's 'Akira' Is Delayed Again\", 'url': 'https://old.reddit.comhttp://collider.com/taika-waititi-thor-4-akira-delayed/'}, {'title': 'Patch 9.14 notes', 'url': 'https://old.reddit.comhttps://na.leagueoflegends.com/en/news/game-updates/patch/patch-914-notes/'}, {'title': 'The view from Micheal’s office today. Currently filming another show at the stages.', 'url': 'https://old.reddit.com/r/DunderMifflin/comments/ce3fqe/the_view_from_micheals_office_today_currently/'}, {'title': 'Ikea is closing its only US factory and moving production to Europe', 'url': 'https://old.reddit.comhttps://www.cnn.com/2019/07/16/business/ikea-us-factory-closing/index.html'}, {'title': 'I grew my hair out for 2 years for this moment. Don’t let me down.', 'url': 'https://old.reddit.com/r/RoastMe/comments/cdwahz/i_grew_my_hair_out_for_2_years_for_this_moment/'}, {'title': 'This photo captures a rare sight of a 65-Foot-tall Lava Dome in Hawaii. Symmetrical dome fountains such as this are hard to come by.', 'url': 'https://old.reddit.com/r/oddlysatisfying/comments/ce42d9/this_photo_captures_a_rare_sight_of_a_65foottall/'}, {'title': 'This definitely belongs here', 'url': 'https://old.reddit.com/r/WatchPeopleDieInside/comments/cdvxcw/this_definitely_belongs_here/'}, {'title': 'Rep. Al Green says he will file articles of impeachment against Trump tonight, despite pushback from Democratic leaders', 'url': 'https://old.reddit.comhttps://www.washingtonpost.com/news/politics/wp/2019/07/16/rep-al-green-says-he-will-file-articles-of-impeachment-against-trump-tonight-despite-pushback-from-democratic-leaders/'}, {'title': \"If you don't like the racism, go home!\", 'url': 'https://old.reddit.com/r/PoliticalHumor/comments/cdw2yg/if_you_dont_like_the_racism_go_home/'}, {'title': 'hmmm', 'url': 'https://old.reddit.comhttps://i.imgur.com/eHQx195.jpg'}, {'title': 'Epic Games donates $1.2M to Blender, an open source 3D software. Meanwhile, gamers donate 1.2 metric tons of popcorn to SRD.', 'url': 'https://old.reddit.com/r/SubredditDrama/comments/cdukbm/epic_games_donates_12m_to_blender_an_open_source/'}, {'title': 'Precious boy tries his best to pet his feline sibling', 'url': 'https://old.reddit.comhttps://gfycat.com/negligibleinbornacornbarnacle'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unM_fzvorolg",
        "colab_type": "text"
      },
      "source": [
        "## dump as json\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzOlSpX1qy9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data.json','w') as outfile:\n",
        "  json.dump(extracted_records,outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpQL9Tn72XDx",
        "colab_type": "text"
      },
      "source": [
        "## Comments and beyond\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaeTHqj-r3jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://old.reddit.com/\"\n",
        "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'\n",
        "request = urllib.request.Request(url,headers={'User-Agent': user_agent})\n",
        "html = urllib.request.urlopen(request).read()\n",
        "soup = BeautifulSoup(html,'html.parser')\n",
        "#First lets get the HTML of the table called site Table where all the links are displayed\n",
        "\n",
        "main_table = soup.find(\"div\",attrs={'id':'siteTable'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P59xvurF3Y9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comment_a_tags = main_table.find_all(\"a\",attrs = {\"class\": \"bylink comments may-blank\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak-wNuv83dqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urls = [] \n",
        "for a_tag in comment_a_tags:\n",
        "    url = a_tag['href']\n",
        "    if not url.startswith('http'):\n",
        "        url = \"https://reddit.com\"+url\n",
        "    urls.append(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoEFJrqm5IKp",
        "colab_type": "text"
      },
      "source": [
        "### Take any comment and find the items you want"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylJD0NGL5CnQ",
        "colab_type": "code",
        "outputId": "bb31a131-043e-4000-c140-aa6eb4126b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "urls[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://old.reddit.com/r/AmItheAsshole/comments/cdypge/aita_for_telling_cashier_that_wasnt_the_girls/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13MfwBHRfj_p",
        "colab_type": "text"
      },
      "source": [
        "we will find\n",
        "* Title\n",
        "* upvotes,\n",
        "* original_poster,\n",
        "* comments_count,\n",
        "* extracted_comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70H8518c5Rws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def url_parser(page_url):\n",
        "  user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'\n",
        "  request = urllib.request.Request(page_url,headers={'User-Agent': user_agent})\n",
        "  html = urllib.request.urlopen(request).read()\n",
        "  soup = BeautifulSoup(html,'html.parser')\n",
        "  \n",
        "  main_post = soup.find(\"div\",attrs = {'id':'siteTable'})\n",
        "  title = main_post.find(\"a\",attrs = {'class':\"title\"})\n",
        "  upvotes = main_post.find(\"div\",attrs = {'class':'unvoted'})\n",
        "  original_poster = main_post.find('a',attrs={'class':'author'}).text\n",
        "  comments_count = main_post.find('a',attrs={'class':'bylink comments may-blank'}).text\n",
        "  comment_area = soup.find('div',attrs={'class':'commentarea'})\n",
        "  comments = comment_area.find_all('div', attrs={'class':'entry unvoted'})\n",
        "  extracted_comments = []\n",
        "  for comment in comments: \n",
        "        if comment.find('form'):\n",
        "            #We are now looking for any element with a class of author in the comment, instead of just looking for a tags. \n",
        "            #We noticed some comments whose authors have deleted their account shows up with a span tag instead of an a \n",
        "            commenter = comment.find(attrs={'class':'author'}).text\n",
        "            comment_text = comment.find('div',attrs={'class':'md'}).text.strip()\n",
        "            permalink = comment.find('a',attrs={'class':'bylink'})['href']\n",
        "            extracted_comments.append({'commenter':commenter,'comment_text':comment_text,'permalink':permalink})\n",
        "    #Lets put the data in dict \n",
        "  post_data = {\n",
        "        'title':str(title),\n",
        "        'no_of_upvotes':str(upvotes),\n",
        "        'poster':str(original_poster),\n",
        "        'no_of_comments':str(comments_count),\n",
        "        'comments':str(extracted_comments)\n",
        "    }\n",
        "  return post_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVhVooODj4Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_x = url_parser(\"https://old.reddit.com/r/AdviceAnimals/comments/ce5yv1/at_work_with_a_coworker_in_a_group_conversation/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBQnBp46myol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11869a8c-a0d8-47d1-dfd9-cc5536a2b4e0"
      },
      "source": [
        "type(json_x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb1SxZ89loX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('comment1.json','w') as jsonfile:\n",
        "  json.dump(json_x,jsonfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gyy0riMiPCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe0cByjViyAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}